{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义一个基本的卷积块，包括卷积、批量归一化和ReLU激活函数\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# 定义ResNet18模型\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# 创建ResNet18模型\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "# 实例化ResNet18模型\n",
    "model = ResNet18()\n",
    "\n",
    "# 打印模型结构\n",
    "# print(model)\n",
    "\n",
    "# 创建一个随机的输入张量，模拟一批次的图像数据\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "# 将输入数据传递给模型，进行前向传播\n",
    "output = model(input)\n",
    "\n",
    "# 打印输出数据\n",
    "print(output.shape)\n",
    "\n",
    "# 检查输出数据的形状是否正确\n",
    "assert output.shape == (1, 10), \"Output shape is incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "torch.Size([64, 64, 112, 112])\n",
      "torch.Size([64, 64, 56, 56])\n",
      "torch.Size([64, 64, 28, 28])\n",
      "torch.Size([64, 64, 14, 14])\n",
      "torch.Size([64, 256, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        # self.strat_conv = nn.Conv2d(1, 3, kernel_size=1)  # 修改卷积核大小和步长以适应224x224的\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 修改卷积核大小和步长以适应224x224的输入\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def padding(self, x):\n",
    "        # 计算需要填充的像素数\n",
    "        padding_height = 224 - x.size(3)\n",
    "        padding_width = 224 - x.size(4)\n",
    "\n",
    "        # 计算在每个方向上需要填充的像素数\n",
    "        padding_top = padding_height // 2\n",
    "        padding_bottom = padding_height - padding_top\n",
    "        padding_left = padding_width // 2\n",
    "        padding_right = padding_width - padding_left\n",
    "\n",
    "        # 使用pad函数填充图像\n",
    "        x = F.pad(x, (padding_left, padding_right, padding_top, padding_bottom), mode='constant', value=0)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.squeeze(self.padding(x))   # 使用padding函数填充输入图像\n",
    "        # x = F.interpolate(x, size=(224, 224), mode='constant', align_corners=False)  # 将输入图像大小使用0值均匀扩充至(224, 224)大小\n",
    "        \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        feat1 = self.layer1(x)\n",
    "        feat2 = self.layer2(feat1)\n",
    "        feat3 = self.layer3(feat2)\n",
    "        feat4 = self.layer4(feat3)\n",
    "        return [feat1, feat2, feat3, feat4]  # 返回各层不同尺度的特征值组成的列表\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3,4,6,3])\n",
    "\n",
    "# torch.Size([3, 64, 112, 112])\n",
    "# torch.Size([3, 128, 56, 56])\n",
    "# torch.Size([3, 256, 28, 28])\n",
    "# torch.Size([3, 512, 14, 14])\n",
    "\n",
    "\n",
    "class BiStreamFPN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiStreamFPN, self).__init__()\n",
    "        self.resnet = ResNet18()\n",
    "        \n",
    "        self.top_down1 = nn.Conv2d(512, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.top_down2 = nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.top_down3 = nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.top_down4 = nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.down_top1 = nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.down_top2 = nn.Conv2d(128, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.down_top3 = nn.Conv2d(256, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self.down_top4 = nn.Conv2d(512, 64, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c2, c3, c4, c5 = self.resnet(x)  # channels : 64, 128, 256, 512\n",
    "        # top down stream\n",
    "        p5 = self.top_down1(c5) \n",
    "        p4 = self.upsample(p5) + self.top_down2(c4)\n",
    "        p3 = self.upsample(p4) + self.top_down3(c3)\n",
    "        p2 = self.upsample(p3) + self.top_down4(c2)\n",
    "        \n",
    "        t2 = self.down_top1(c2)\n",
    "        t3 = F.interpolate(t2, scale_factor=0.5, mode='nearest') + self.down_top2(c3)\n",
    "        t4 = F.interpolate(t3, scale_factor=0.5, mode='nearest') + self.down_top3(c4)\n",
    "        t5 = F.interpolate(t4, scale_factor=0.5, mode='nearest') + self.down_top4(c5)\n",
    "        \n",
    "        return [ p2 + t2, p3 + t3, p4 + t4, p5 + t5]\n",
    "\n",
    "\n",
    "class MultiScaleFusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiScaleFusion, self).__init__()\n",
    "        self._1conv = nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "        self._2conv = nn.Conv2d(64, 64, kernel_size=2, stride=2, padding=0)\n",
    "        self._4conv = nn.Conv2d(64, 64, kernel_size=4, stride=4, padding=0)\n",
    "        self._8conv = nn.Conv2d(64, 64, kernel_size=8, stride=8, padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4 = x\n",
    "        x1 = self._8conv(x1)\n",
    "        x2 = self._4conv(x2)\n",
    "        x3 = self._2conv(x3)\n",
    "        x4 = self._1conv(x4)\n",
    "        return torch.cat((x1, x2, x3, x4), dim=1)\n",
    "    \n",
    "# 实例化ResNet18模型\n",
    "model = BiStreamFPN()\n",
    "\n",
    "fusion = MultiScaleFusion()\n",
    "\n",
    "# 打印模型结构\n",
    "# print(model)\n",
    "\n",
    "# 创建一个随机的输入张量，模拟一批次的图像数据\n",
    "input = torch.randn(64, 3, 1, 162, 209)\n",
    "\n",
    "output = model(input)\n",
    "\n",
    "# 打印输出数据\n",
    "print(type(output))\n",
    "print(output[0].shape)\n",
    "print(output[1].shape)\n",
    "print(output[2].shape)\n",
    "print(output[3].shape)\n",
    "\n",
    "final = fusion(output)\n",
    "print(final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([64, 64, 112, 112])\n",
    "# torch.Size([64, 64, 56, 56])\n",
    "# torch.Size([64, 64, 28, 28])\n",
    "# torch.Size([64, 64, 14, 14])\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "a = torch.rand([64, 64, 112, 112])\n",
    "b = torch.rand([64, 64, 56, 56])\n",
    "c = torch.rand([64, 64, 28, 28])\n",
    "d = torch.rand([64, 64, 14, 14])\n",
    "\n",
    "_1conv = nn.Conv2d(64, 64, kernel_size=1, stride=1, padding=0)\n",
    "_3conv = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)\n",
    "_5conv = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=0)\n",
    "_7conv = nn.Conv2d(64, 64, kernel_size=7, stride=7, padding=0)\n",
    "\n",
    "a = _7conv(a)\n",
    "\n",
    "print(a.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

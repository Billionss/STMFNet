{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 98, 98])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MultiModalAttentionFusion(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, embed_dim, num_heads=4):\n",
    "        super(MultiModalAttentionFusion, self).__init__()\n",
    "        self.dim_x = dim_x\n",
    "        self.dim_y = dim_y\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        self.query_modalA = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_modalA = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        self.query_modalB = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key_modalB = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, modalA, modalB):\n",
    "        \n",
    "        # [N, len_a, embed_dim]\n",
    "        # [N, len_b, embed_dim]\n",
    "        N = modalA.shape[0]\n",
    "\n",
    "        qlen_A , klen_A= modalA.shape[1], modalA.shape[1]\n",
    "        qlen_B, klen_B = modalB.shape[1], modalB.shape[1]\n",
    "        \n",
    "        query_A = self.query_modalA(modalA)\n",
    "        key_A = self.key_modalA(modalA)\n",
    "        \n",
    "        query_B = self.query_modalB(modalB)\n",
    "        key_B = self.key_modalB(modalB)\n",
    "        \n",
    "        # [N, len_a, num_heads, head_dim]\n",
    "        query_A = query_A.view(N, qlen_A, self.num_heads, self.head_dim)\n",
    "        key_A = key_A.view(N, klen_A, self.num_heads, self.head_dim)\n",
    "        \n",
    "        query_B = query_B.view(N, qlen_B, self.num_heads, self.head_dim)\n",
    "        key_B = key_B.view(N, klen_B, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Self Modal Attention \n",
    "        attn_A = torch.mean( torch.einsum('nqhd,nkhd->nhqk', query_A, key_A), dim=1) \n",
    "        attn_B = torch.mean( torch.einsum('nqhd,nkhd->nhqk', query_B, key_B), dim=1) \n",
    "        \n",
    "        weighted_A = F.softmax(attn_A / (self.embed_dim ** (1/2)  ), dim=-1)\n",
    "        weighted_B = F.softmax(attn_B / (self.embed_dim ** (1/2)  ), dim=-1)\n",
    "        \n",
    "        # Cross Modal Attention\n",
    "        attn_AB = torch.mean( torch.einsum('nqhd,nkhd->nhqk', query_A, key_B), dim=1) \n",
    "        attn_BA = torch.mean( torch.einsum('nqhd,nkhd->nhqk', query_B, key_A), dim=1) \n",
    "        \n",
    "        weighted_AB = F.softmax(attn_AB / (self.embed_dim ** (1/2)  ), dim=-1)\n",
    "        weighted_BA = F.softmax(attn_BA / (self.embed_dim ** (1/2)  ), dim=-1)\n",
    "        \n",
    "        cat_upper = torch.cat([weighted_B, weighted_BA], dim=-1)  # [34, 34] [34, 64] --> [34, 98]\n",
    "        cat_lower = torch.cat([weighted_A, weighted_AB], dim=-1)  # [64, 64] [64, 34] --> [64, 98]\n",
    "        \n",
    "        cat = torch.cat([cat_lower, cat_upper], dim=1)\n",
    "        return cat\n",
    "    \n",
    "\n",
    "    a = torch.rand([64, 64, 256])\n",
    "    b = torch.rand([64, 34, 256])\n",
    "\n",
    "    fusion = MultiModalAttentionFusion(dim_x=64, dim_y=34, embed_dim=256)\n",
    "\n",
    "    cat  = fusion(a, b)\n",
    "    print(cat.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 98, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = torch.rand([32, 34+64, 256])\n",
    "\n",
    "support = torch.rand([32, 34+64, 34+64])\n",
    "\n",
    "gcn = torch.einsum('ncf,ncc->ncf', (a, support))\n",
    "\n",
    "print(gcn.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # return torch.einsum('ncvl,vw->ncwl', (x, A)).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0025, 0.0025, 0.0025],\n",
      "         [0.9526, 0.9526, 0.8808]],\n",
      "\n",
      "        [[0.9975, 0.9975, 0.9975],\n",
      "         [0.0474, 0.0474, 0.1192]]], dtype=torch.float64)\n",
      "tensor([[[0.0474, 0.0474, 0.0474],\n",
      "         [0.9526, 0.9526, 0.9526]],\n",
      "\n",
      "        [[0.9975, 0.9975, 0.9933],\n",
      "         [0.0025, 0.0025, 0.0067]]], dtype=torch.float64)\n",
      "tensor([[[0.0900, 0.2447, 0.6652],\n",
      "         [0.0900, 0.2447, 0.6652]],\n",
      "\n",
      "        [[0.0900, 0.2447, 0.6652],\n",
      "         [0.0420, 0.1142, 0.8438]]], dtype=torch.float64)\n",
      "tensor([[[0.0900, 0.2447, 0.6652],\n",
      "         [0.0900, 0.2447, 0.6652]],\n",
      "\n",
      "        [[0.0900, 0.2447, 0.6652],\n",
      "         [0.0420, 0.1142, 0.8438]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    " \n",
    "a = [[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [1, 2, 4]]]\n",
    "a = torch.from_numpy(np.array(a, dtype=float))\n",
    "b1 = F.softmax(a, dim=0)\n",
    "b2 = F.softmax(a, dim=1)\n",
    "b3 = F.softmax(a, dim=2)\n",
    "b4 = F.softmax(a, dim=-1)\n",
    "print(b1)\n",
    "print(b2)\n",
    "print(b3)\n",
    "print(b4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
